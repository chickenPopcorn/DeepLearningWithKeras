{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"//fonts.googleapis.com/css?family=Quicksand:300\" />\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"custom.css\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"//fonts.googleapis.com/css?family=Quicksand:300\" />\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hands-on introduction to Deep Learning\n",
    "with Keras and Tensorflow\n",
    "\n",
    "### Goals\n",
    "- Learn the basic theory about deep learning.\n",
    "- Learn Build different favors of Keras deep learning model.\n",
    "- Learn to implement transfer learning in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "\n",
    "|                      \t                                |              |\n",
    "|:------------------------------------------------------|:-------------|\n",
    "| Course Introduction                                   |              |\n",
    "| [Deep learning basics](01_01_deep_learning_basics.ipynb) | Theory       |\n",
    "| [Deep learning with Keras](02_deep_learning_with_keras.ipynb) | Theory       |\n",
    "| [Basics_of_keras_NN.ipynb](03_01_basics_of_keras_NN.ipynb) | Hands-on |\n",
    "| [Basics_of_keras_convnet.ipynb](04_basics_of_keras_convnet.ipynb) | Hands-on |\n",
    "| Coming Soon        | Hands-on |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"520\" height=\"300\" src=\"https://www.youtube.com/embed/l9RWTMNnvi4\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Youtube\n",
    "HTML('<iframe width=\"520\" height=\"300\" src=\"https://www.youtube.com/embed/l9RWTMNnvi4\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Overview\n",
    "\n",
    "\n",
    "### AI, ML, and Deep Learning\n",
    "- Subfield of machine learning that uses algorithms inspired by the structure and function of the brain’s neural networks\n",
    "- Analyze data, learn from that data, and then make a determination or prediction about new data.\n",
    "\n",
    "![three_quarters center](images/deep_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# ML vs Deep Learning\n",
    "\n",
    "### Advantage\n",
    "- Best-in-class performance\n",
    "- Reduces feature engineering (most time-consuming parts of ML)\n",
    "- Architecture that can be adapted to new problems more easily\n",
    "\n",
    "![three_quarters center](images/machine-learning-vs-deep-learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning over the years\n",
    "\n",
    "![three_quarters center](images/dl_timeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Deep Learning over the years\n",
    "\n",
    "- **1958 - Percentron unit - Frank Rosenblatt**\n",
    "- **1986 - Backpropagation - Geoffrey Hinton**\n",
    "- **1986 - RNN - Schuster & Pallwal**\n",
    "- 1989 - LeNet Backpropagation to multi-layer perceptron - Yan LeCun\n",
    "- 1997 - LSTM - Sepp Hochreiter and Jürgen Schmidhuber\n",
    "- **1998 - LeNet-5 Convolutional neural networks - YanLecun**\n",
    "- 2007 - Fei Fei Li Princeton ImageNet competition\n",
    "- 2009 - GPU for deep learning - Andrew Ng\n",
    "- **2011 - Demonstration of ReLu for deep neural networks - Yoshua Bengio**\n",
    "- **2012 - AlexNet wins ImageNet 25% to 16% error**\n",
    "- **2012 - Dropout technique - Geoffrey Hinton**\n",
    "- 2014 - Generative adversarial networks - Ian Goodfellow & Yoshua Bengio\n",
    "- 2015 - CNN beats human error in ImageNet 5% to 3%\n",
    "- 2016 - AlphaGo - Google DeepMind\n",
    "- 2016 - Detectic metatastic cancer beats human pathologist .96 to 0.99 AUC\n",
    "- 2017 - Capsule networks - Geoffrey Hinton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Neural Network\n",
    "\n",
    "### Advantage\n",
    "- Best-in-class performance\n",
    "- Reduces feature engineering (most time-consuming parts of ML)\n",
    "- Architecture that can be adapted to new problems more easily\n",
    "![center half](images/dnn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Deep Neural Network\n",
    "\n",
    "![neuron_comparison center half](images/neuron_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Artificial Neuron\n",
    "\n",
    "![artificial_neuron center half](images/artificial_neuron.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Neural Networks - Components\n",
    "\n",
    "![dnn center half](images/dnn_labels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# Layers\n",
    "\n",
    "Hierarchical feature representations\n",
    "\n",
    "![layers center](images/layers.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Artificial Neuron\n",
    "\n",
    "### Neuron Firing - Activation and Propagation\n",
    "\n",
    "![neuron_fire center half](images/neuron_fire.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Artificial Neuron\n",
    "\n",
    "![neuron half](images/neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Activation\n",
    "\n",
    "### Activation Functions -> $ f(x) $\n",
    "\n",
    "![activation center half](images/activation.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forward pass\n",
    "\n",
    "\n",
    "![center half](images/forward_pass_1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Forward pass\n",
    "\n",
    "\n",
    "![center half](images/forward_pass_2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "\n",
    "\n",
    "![center half](images/backpropagation_0.gif)\n",
    "\n",
    "<sub>*Ryszard Tadeusiewcz \"Sieci neuronowe\", Kraków 1992*</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "\n",
    "\n",
    "![center half](images/backpropagation_1.gif)\n",
    "\n",
    "<sub>*Ryszard Tadeusiewcz \"Sieci neuronowe\", Kraków 1992*</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "\n",
    "\n",
    "![center half](images/backpropagation_2.gif)\n",
    "\n",
    "<sub>*Ryszard Tadeusiewcz \"Sieci neuronowe\", Kraków 1992*</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "\n",
    "\n",
    "![center half](images/backpropagation_3.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "\n",
    "\n",
    "Starts at the end of the net and tunes each layer using the gradient of the loss function. Repeatedly applies the chain rule. \n",
    "\n",
    "**Numeric approximation** $f'(x) \\approx \\frac{f(x+h) - f(x)}{h}$\n",
    "\n",
    "**Symbolic differentiation** Symbolic, exact representation of the derivative.\n",
    "\n",
    "**Reverse automatic differentiation**\n",
    "\n",
    "![center](images/automatic-differentiation.png)\n",
    "\n",
    "<sup>Source: [Automatic Differentiation](http://www.columbia.edu/~ahd2125/post/2015/12/5/)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Optimization\n",
    "\n",
    "1. Loss/cost function\n",
    "2. Gradient descent\n",
    "3. Learning rate\n",
    "4. Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Gradient descent\n",
    "\n",
    "![optimizers_1 center half](images/gradient_descent.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Gradient descent\n",
    "\n",
    "###  Learning Rate\n",
    "\n",
    " \n",
    "![learning_rate center half](images/learning_rate.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Gradient descent\n",
    "\n",
    "###  Optimizers\n",
    " 1. **Stochastic gradient descent (SGD)**\n",
    " 2. SGD + momentum\n",
    " 3. SGD + Nesterov\n",
    " 4. AdaGrad\n",
    " 5. **RMSProp**\n",
    " 6. **Adam**\n",
    " 7. Nadam\n",
    " \n",
    "![optimizers_1 left half](images/optimizers_1.gif)\n",
    "![optimizers_3 right half](images/optimizers_3.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# When to use neural nets?\n",
    "\n",
    "** Data types**\n",
    "\n",
    "- **Structured data**\n",
    "    - Handcrafted feature engineering\n",
    "    - Boosting algoritms\n",
    "\n",
    "- **Unstructured data** \n",
    "    - (images/text/signals) use neural networks and deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Architecture\n",
    "\n",
    "![neural_networks_collection](images/neural_networks_collection.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recommended literature\n",
    "\n",
    "![center quarter](images/dl_book.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NEXT [Deep Learning Basics](01_02_deep_learning_basics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
